{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dce22860-703a-46b9-8ac5-4dc8c1e8e7ac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "069f8bd0-4840-433f-9242-91078a156a40",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data = [\n",
    "    Row(id=1, name=\"Aarav\", gender=\"Male\", salary=50000, department=\"IT\", place=\"Mumbai\"),\n",
    "    Row(id=2, name=\"Anaya\", gender=\"Female\", salary=55000, department=\"HR\", place=\"Delhi\"),\n",
    "    Row(id=3, name=\"Vivaan\", gender=\"Male\", salary=60000, department=\"Finance\", place=\"Bangalore\"),\n",
    "    Row(id=4, name=\"Diya\", gender=\"Female\", salary=50000, department=\"IT\", place=\"Chennai\"),\n",
    "    Row(id=5, name=\"Aditya\", gender=\"Male\", salary=58000, department=\"Marketing\", place=\"Hyderabad\"),\n",
    "    Row(id=6, name=\"Ishita\", gender=\"Female\", salary=58000, department=\"Sales\", place=\"Pune\"),\n",
    "    Row(id=7, name=\"Arjun\", gender=\"Male\", salary=62000, department=\"IT\", place=\"Kolkata\"),\n",
    "    Row(id=8, name=\"Aditi\", gender=\"Female\", salary=54000, department=\"HR\", place=\"Ahmedabad\"),\n",
    "    Row(id=9, name=\"Kabir\", gender=\"Male\", salary=61000, department=\"Finance\", place=\"Surat\"),\n",
    "    Row(id=10, name=\"Meera\", gender=\"Female\", salary=56000, department=\"IT\", place=\"Jaipur\"),\n",
    "    Row(id=11, name=\"Rohan\", gender=\"Male\", salary=59000, department=\"Marketing\", place=\"Lucknow\"),\n",
    "    Row(id=12, name=\"Saanvi\", gender=\"Female\", salary=57000, department=\"Sales\", place=\"Kanpur\"),\n",
    "    Row(id=13, name=\"Aryan\", gender=\"Male\", salary=63000, department=\"IT\", place=\"Nagpur\"),\n",
    "    Row(id=14, name=\"Nisha\", gender=\"Female\", salary=55000, department=\"HR\", place=\"Indore\"),\n",
    "    Row(id=15, name=\"Krishna\", gender=\"Male\", salary=64000, department=\"Finance\", place=\"Bhopal\")\n",
    "]\n",
    "\n",
    "df = spark.createDataFrame(data)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cbdcb136-3684-4547-bdf5-b9f53a588eb2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import avg\n",
    "\n",
    "avg_salary = df.select(avg(\"salary\"))\n",
    "display(avg_salary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "26801854-c715-40cd-b95c-db1da712e094",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1757490582139}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import count\n",
    "\n",
    "count_rows = df.filter(df.department == \"HR\").groupBy(\"name\").agg(count(\"*\").alias(\"count\"))\n",
    "display(count_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f5cdd049-4669-4909-a874-e3bd74fa712c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import countDistinct\n",
    "\n",
    "distinct_count_it = df.filter(df.department == \"IT\").groupBy(\"department\").agg(countDistinct(\"id\").alias(\"distinct_count\"))\n",
    "display(distinct_count_it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f4dfd2af-354b-4702-9fc9-28f6ece86baa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import sum\n",
    "\n",
    "salary1 = df.select(sum(\"salary\").alias(\"salary1\"))\n",
    "display(salary1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ce83c5d8-06b7-415e-8ea9-6cb46368cfc3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import min, max\n",
    "\n",
    "min_salary = df.select(min(\"salary\").alias(\"min_salary\"))\n",
    "max_salary = df.select(max(\"salary\").alias(\"max_salary\"))\n",
    "\n",
    "display(min_salary)\n",
    "display(max_salary)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "pyspark_aggregate_function",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
